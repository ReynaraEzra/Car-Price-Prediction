# -*- coding: utf-8 -*-
"""Project Iris.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1m9zlMTLhmthKseuQUFwS1PIxePkQ1uNj

# **Reynara Ezra Pratama**
"""

import pandas as pd
import numpy as np

# Commented out IPython magic to ensure Python compatibility.
!pip install ipython-autotime
# %load_ext autotime

path = "/content/Iris.csv"
df = pd.read_csv(path)

print(df.shape)

df.head()

df.tail()

df.describe()

df.describe(include='all')

df.drop('Id', axis=1, inplace=True)

df['Species'].value_counts()

import matplotlib.pyplot as plt

df[['PetalLengthCm', 'PetalWidthCm', 'SepalLengthCm', 'SepalWidthCm']].plot(kind='box', subplots=True, layout=(2,2))
plt.show()

df[['PetalLengthCm', 'PetalWidthCm', 'SepalLengthCm', 'SepalWidthCm']].plot(kind='hist', subplots=True, layout=(2,2))
plt.show()

df[['PetalLengthCm', 'PetalWidthCm', 'SepalLengthCm', 'SepalWidthCm']].hist()
plt.show()

from sklearn.model_selection import train_test_split
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score

data = df.values

X = data[:,0:4]
Y = data[:,4]
val_size = 0.2
seed = 7

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=val_size, random_state=seed)

from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score

from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC

models = []
models.append(('LR', LogisticRegression()))
models.append(('CART', DecisionTreeClassifier()))
models.append(('KNN', KNeighborsClassifier()))
models.append(('LDA', LinearDiscriminantAnalysis()))
models.append(('NB', GaussianNB()))
models.append(('SVM', SVC()))

scores = []
names = []

for name, model in models:
  kfold = KFold(n_splits=10, random_state=seed)
  cv_score = cross_val_score(model, X_train, Y_train, cv=kfold, scoring='accuracy')
  scores.append(cv_score)
  names.append(name)

for i in range(6):
  print('Model :', names[i])
  print('Accuracy :', scores[i].mean())
  print('Std :', scores[i].std())
  print('\n')

fig = plt.figure()
fig.suptitle('Algorithm Comparison')
ax = fig.add_subplot(111)
plt.boxplot(scores)
ax.set_xticklabels(names)
plt.show()

